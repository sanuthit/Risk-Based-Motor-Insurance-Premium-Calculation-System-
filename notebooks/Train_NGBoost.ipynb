{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "420798d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from ngboost import NGBoost\n",
    "from ngboost.distns import Bernoulli\n",
    "from ngboost.scores import LogScore\n",
    "import joblib, os\n",
    "\n",
    "df = pd.read_csv(\"../DataSets/processed/risk_dataset_model.csv\")\n",
    "TARGET = \"had_claim_within_1_year\"\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET].astype(int)\n",
    "\n",
    "cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a4dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X_train_enc = preprocessor.fit_transform(X_train)\n",
    "X_val_enc = preprocessor.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbbea103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.5624 val_loss=0.0000 scale=8.0000 norm=3.0005\n",
      "[iter 100] loss=0.5337 val_loss=0.0000 scale=8.0000 norm=2.8581\n",
      "[iter 200] loss=0.5307 val_loss=0.0000 scale=8.0000 norm=2.8292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ngboost.ngboost.NGBoost at 0x16830d67890>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngb = NGBoost(\n",
    "    Dist=Bernoulli,\n",
    "    Score=LogScore,\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.03,\n",
    "    natural_gradient=False,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "ngb.fit(X_train_enc, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "665931a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGBoost ROC-AUC: 0.6416\n",
      "Uncertainty std: [0.26031858 0.37834135 0.4239344  0.46260245 0.49999997]\n"
     ]
    }
   ],
   "source": [
    "dist = ngb.pred_dist(X_val_enc)\n",
    "\n",
    "raw = dist.params if hasattr(dist, \"params\") else dist.params_\n",
    "p = np.asarray(raw[\"p1\"]).reshape(-1)   # ✅ p1 = claim prob\n",
    "\n",
    "auc = roc_auc_score(y_val, p)\n",
    "print(\"NGBoost ROC-AUC:\", round(auc, 4))\n",
    "\n",
    "uncertainty_std = np.sqrt(p * (1 - p))\n",
    "print(\"Uncertainty std:\", np.percentile(uncertainty_std, [0,25,50,75,100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3104e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = ngb.pred_dist(X_val_enc)\n",
    "\n",
    "raw = dist.params if hasattr(dist, \"params\") else dist.params_\n",
    "y_val_prob = np.asarray(raw[\"p1\"]).reshape(-1)   # ✅ claim probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5c278a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGBoost ROC-AUC: 0.6416\n",
      "Best F1 threshold: 0.2176232922548145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Claim       0.84      0.48      0.61      8999\n",
      "       Claim       0.32      0.72      0.44      3001\n",
      "\n",
      "    accuracy                           0.54     12000\n",
      "   macro avg       0.58      0.60      0.53     12000\n",
      "weighted avg       0.71      0.54      0.57     12000\n",
      "\n",
      "Confusion:\n",
      " [[4322 4677]\n",
      " [ 834 2167]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "auc = roc_auc_score(y_val, y_val_prob)\n",
    "print(\"NGBoost ROC-AUC:\", round(auc, 4))\n",
    "\n",
    "# Threshold from F1-max (objective)\n",
    "prec, rec, thr = precision_recall_curve(y_val, y_val_prob)\n",
    "f1 = (2*prec*rec)/(prec+rec+1e-9)\n",
    "\n",
    "best_idx = np.argmax(f1)\n",
    "best_threshold_f1 = thr[best_idx]\n",
    "print(\"Best F1 threshold:\", float(best_threshold_f1))\n",
    "\n",
    "# Report @ best threshold\n",
    "y_pred = (y_val_prob >= best_threshold_f1).astype(int)\n",
    "print(classification_report(y_val, y_pred, target_names=[\"No Claim\", \"Claim\"]))\n",
    "print(\"Confusion:\\n\", confusion_matrix(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c464f33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../models/ngboost_bundle.pkl\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(\n",
    "    {\n",
    "        \"model\": ngb,\n",
    "        \"preprocessor\": preprocessor\n",
    "    },\n",
    "    \"../models/ngboost_bundle.pkl\"\n",
    ")\n",
    "\n",
    "print(\"Saved: ../models/ngboost_bundle.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88b99244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cost-based threshold: 0.17210526315789476  | cost: 8424.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def best_threshold_by_cost(y_true, y_prob, fn_cost=5.0, fp_cost=1.0, grid_size=400):\n",
    "    thresholds = np.linspace(0.01, 0.99, grid_size)\n",
    "    costs = []\n",
    "    for t in thresholds:\n",
    "        y_pred = (y_prob >= t).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        cost = fn_cost * fn + fp_cost * fp\n",
    "        costs.append(cost)\n",
    "    best_idx = int(np.argmin(costs))\n",
    "    return float(thresholds[best_idx]), float(costs[best_idx])\n",
    "\n",
    "# Example (insurance: FN is worse than FP)\n",
    "best_t_cost, best_cost = best_threshold_by_cost(y_val, y_val_prob, fn_cost=5, fp_cost=1)\n",
    "print(\"Best cost-based threshold:\", best_t_cost, \" | cost:\", best_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "902a132f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F2 threshold: 0.13540047450527778  | F2: 0.6312629670660074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "def best_threshold_fbeta(y_true, y_prob, beta=2.0):\n",
    "    p, r, thr = precision_recall_curve(y_true, y_prob)\n",
    "    fbeta = (1 + beta**2) * (p * r) / ((beta**2 * p) + r + 1e-9)\n",
    "    best_idx = np.argmax(fbeta)\n",
    "    return float(thr[best_idx]), float(fbeta[best_idx])\n",
    "\n",
    "best_t_f2, best_f2 = best_threshold_fbeta(y_val, y_val_prob, beta=2.0)\n",
    "print(\"Best F2 threshold:\", best_t_f2, \" | F2:\", best_f2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd475495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.7813 val_loss=0.0000 scale=8.0000 norm=2.8170\n",
      "[iter 100] loss=0.6458 val_loss=0.0000 scale=8.0000 norm=3.6646\n",
      "[iter 200] loss=0.6433 val_loss=0.0000 scale=8.0000 norm=3.6562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ngboost.ngboost.NGBoost at 0x16830d67890>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "sw = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "\n",
    "ngb.fit(X_train_enc, y_train, sample_weight=sw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30fd9d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COST-BASED (FN=5, FP=1)\n",
      "Threshold: 0.17210526315789476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Claim       0.87      0.29      0.43      8999\n",
      "       Claim       0.29      0.87      0.43      3001\n",
      "\n",
      "    accuracy                           0.43     12000\n",
      "   macro avg       0.58      0.58      0.43     12000\n",
      "weighted avg       0.72      0.43      0.43     12000\n",
      "\n",
      "Confusion:\n",
      " [[2565 6434]\n",
      " [ 398 2603]]\n",
      "\n",
      "F2-OPTIMAL (recall-focused)\n",
      "Threshold: 0.13540047450527778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Claim       0.90      0.13      0.23      8999\n",
      "       Claim       0.27      0.95      0.42      3001\n",
      "\n",
      "    accuracy                           0.34     12000\n",
      "   macro avg       0.58      0.54      0.33     12000\n",
      "weighted avg       0.74      0.34      0.28     12000\n",
      "\n",
      "Confusion:\n",
      " [[1210 7789]\n",
      " [ 141 2860]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def report_at_threshold(y_true, y_prob, t, title=\"\"):\n",
    "    y_pred = (y_prob >= t).astype(int)\n",
    "    print(\"\\n\" + title)\n",
    "    print(\"Threshold:\", t)\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"No Claim\",\"Claim\"]))\n",
    "    print(\"Confusion:\\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# 1) Cost-based threshold\n",
    "t_cost, _ = best_threshold_by_cost(y_val, y_val_prob, fn_cost=5, fp_cost=1)\n",
    "report_at_threshold(y_val, y_val_prob, t_cost, title=\"COST-BASED (FN=5, FP=1)\")\n",
    "\n",
    "# 2) F2 threshold\n",
    "t_f2, _ = best_threshold_fbeta(y_val, y_val_prob, beta=2.0)\n",
    "report_at_threshold(y_val, y_val_prob, t_f2, title=\"F2-OPTIMAL (recall-focused)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23d740a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from ngboost import NGBoost\n",
    "from ngboost.distns import Bernoulli\n",
    "from ngboost.scores import LogScore\n",
    "import joblib, os\n",
    "\n",
    "df = pd.read_csv(\"../DataSets/processed/risk_dataset_model.csv\")\n",
    "\n",
    "TARGET = \"had_claim_within_1_year\"\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8feb126b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded train shape: (48000, 60)\n",
      "Encoded val shape  : (12000, 60)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) One-hot encode categorical columns\n",
    "X_train_enc = pd.get_dummies(X_train, drop_first=False)\n",
    "X_val_enc   = pd.get_dummies(X_val, drop_first=False)\n",
    "\n",
    "# 2) Align columns (important!)\n",
    "X_train_enc, X_val_enc = X_train_enc.align(X_val_enc, join=\"left\", axis=1, fill_value=0)\n",
    "\n",
    "# 3) Make sure y is int 0/1\n",
    "y_train_int = y_train.astype(int)\n",
    "y_val_int   = y_val.astype(int)\n",
    "\n",
    "print(\"Encoded train shape:\", X_train_enc.shape)\n",
    "print(\"Encoded val shape  :\", X_val_enc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ec04feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.5624 val_loss=0.0000 scale=8.0000 norm=3.0005\n",
      "[iter 100] loss=0.5337 val_loss=0.0000 scale=8.0000 norm=2.8579\n",
      "[iter 200] loss=0.5307 val_loss=0.0000 scale=8.0000 norm=2.8295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ngboost.ngboost.NGBoost at 0x231fff2f610>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngb_model = NGBoost(\n",
    "    Dist=Bernoulli,\n",
    "    Score=LogScore,\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.03,\n",
    "    natural_gradient=False,   \n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "ngb_model.fit(X_train_enc, y_train_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62242ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability summary:\n",
      "count    12000.000000\n",
      "mean         0.250659\n",
      "std          0.101648\n",
      "min          0.071337\n",
      "25%          0.172999\n",
      "50%          0.234657\n",
      "75%          0.310324\n",
      "max          0.703310\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "dist = ngb_model.pred_dist(X_val_enc)\n",
    "\n",
    "# NGBoost returns both class probabilities\n",
    "raw = dist.params if hasattr(dist, \"params\") else dist.params_\n",
    "\n",
    "# Claim probability = p1\n",
    "y_val_prob_ngb = np.asarray(raw[\"p1\"]).reshape(-1)\n",
    "\n",
    "print(\"Probability summary:\")\n",
    "print(pd.Series(y_val_prob_ngb).describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b508d141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGBoost ROC-AUC: 0.6412\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\n",
    "    \"NGBoost ROC-AUC:\",\n",
    "    round(roc_auc_score(y_val_int, y_val_prob_ngb), 4)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43a5edb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ngb = (y_val_prob_ngb >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e60d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy              : 0.7493\n",
      "Balanced Accuracy     : 0.5142\n",
      "Precision (Claim)     : 0.487\n",
      "Recall (Claim)        : 0.0437\n",
      "F1-score (Claim)      : 0.0801\n",
      "\n",
      "Confusion Matrix:\n",
      "[[8861  138]\n",
      " [2870  131]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Claim       0.76      0.98      0.85      8999\n",
      "       Claim       0.49      0.04      0.08      3001\n",
      "\n",
      "    accuracy                           0.75     12000\n",
      "   macro avg       0.62      0.51      0.47     12000\n",
      "weighted avg       0.69      0.75      0.66     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "print(\"Accuracy              :\", round(accuracy_score(y_val_int, y_pred_ngb), 4))\n",
    "print(\"Balanced Accuracy     :\", round(balanced_accuracy_score(y_val_int, y_pred_ngb), 4))\n",
    "print(\"Precision (Claim)     :\", round(precision_score(y_val_int, y_pred_ngb), 4))\n",
    "print(\"Recall (Claim)        :\", round(recall_score(y_val_int, y_pred_ngb), 4))\n",
    "print(\"F1-score (Claim)      :\", round(f1_score(y_val_int, y_pred_ngb), 4))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val_int, y_pred_ngb))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_val_int,\n",
    "    y_pred_ngb,\n",
    "    target_names=[\"No Claim\", \"Claim\"]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7e5473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGBoost bundle saved correctly\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import joblib, os\n",
    "\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "ngboost_bundle = {\n",
    "    \"model\": ngb_model,                       # trained NGBoost\n",
    "    \"feature_columns\": X_train_enc.columns.tolist(),\n",
    "    \"model_type\": \"NGBoost-Bernoulli\",\n",
    "    \"note\": \"Final NGBoost risk model with one-hot encoded features\"\n",
    "}\n",
    "\n",
    "joblib.dump(ngboost_bundle, \"../models/ngboost_risk_bundle.pkl\")\n",
    "\n",
    "print(\"NGBoost bundle saved correctly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bde72e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
